{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyi/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "num_input = 6\n",
    "timesteps = 100 # timesteps\n",
    "num_hidden = 100 # hidden layer num of features\n",
    "num_output= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_sensor(filename):\n",
    "    with open(filename, \"r\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        dataset = [row[17:23] for row in reader]\n",
    "        return np.array(dataset)\n",
    "    \n",
    "def read_xml(filename, length):\n",
    "    f = open(filename)\n",
    "    cts = f.read()\n",
    "    f.close()\n",
    "\n",
    "    p_foot = re.compile(r'<WhichFoot>(.*?)</WhichFoot>')\n",
    "    all_foot = p_foot.findall(cts)\n",
    "\n",
    "    p_time = re.compile(r'<Time>(.*?)</Time>')\n",
    "    all_time = p_time.findall(cts)\n",
    "\n",
    "    strike_times = []\n",
    "    #L-1 R-0\n",
    "    strike_times.append([0.0, 0.5])\n",
    "    for i in range(len(all_foot)):\n",
    "        if(all_foot[i]=='L'):\n",
    "            strike_times.append([float(all_time[i]), 1])\n",
    "        else:\n",
    "            strike_times.append([float(all_time[i]), 0])\n",
    "    strike_times[-1][1] = 0.5\n",
    "    strike_times.append([length/25.0, 0.5])\n",
    "\n",
    "    window_y = []\n",
    "    strike_index=0\n",
    "    for i in range(length):\n",
    "        if(i/25.0 >= strike_times[strike_index+1][0]):\n",
    "            strike_index += 1\n",
    "        window_y.append([strike_times[strike_index][1]])\n",
    "\n",
    "    p_info = re.compile(r'<StartTime>(.*?)</StartTime>\\n\\t<EndTime>(.*?)</EndTime>\\n\\t<NSteps>(.*?)</NSteps>\\n\\t<Direction>(.*?)</Direction>')\n",
    "    all_info = p_info.findall(cts)#start_time, end_time, step_num, direction=turn\n",
    "\n",
    "    for i in range(len(all_info)):\n",
    "        if(all_info[i][3][:4]=='Turn'):\n",
    "#             print(all_info[i])\n",
    "            start_time = int(float(all_info[i][0])*25)\n",
    "            end_time = int(float(all_info[i][1])*25)\n",
    "#             print('start and end time : ', all_info[i][0], all_info[i][1])\n",
    "            for t in range(start_time-1, end_time):\n",
    "                window_y[t] = [0.5]\n",
    "\n",
    "    p_feature = re.compile(r'<Feature>\\n\\t\\t\\t<StartTime>(.*?)</StartTime>\\n\\t\\t\\t<EndTime>(.*?)</EndTime>')\n",
    "    all_feature = p_feature.findall(cts)#start_time, end_time, step_num, direction=turn\n",
    "\n",
    "    for i in range(len(all_feature)):\n",
    "        start_time = int(float(all_feature[i][0])*25)\n",
    "        end_time = int(float(all_feature[i][1])*25)\n",
    "        for t in range(start_time-1, end_time):\n",
    "            window_y[t] = [0.5]\n",
    "            \n",
    "#     print(len(window_y))  \n",
    "    return window_y\n",
    "\n",
    "def add_data(path, person, phone_location, assistant):\n",
    "    data_x = read_sensor('weallwalk/sensor/iPhoneSensors_T'+str(path)+'_ID'+str(person)+'_'+phone_location+'_'+assistant+'.csv')\n",
    "    data_y = read_xml('weallwalk/xml/T'+str(path)+'_ID'+str(person)+'_'+assistant+'.xml', len(data_x))\n",
    "    \n",
    "    split_x, split_x_part = [], []\n",
    "    split_y, split_y_part = [], []\n",
    "    for i in range(len(data_y)):\n",
    "        if(data_y[i][0]!=0.5):\n",
    "            split_y_part.append(data_y[i])\n",
    "            split_x_part.append(data_x[i])\n",
    "        else:\n",
    "            if(len(split_y_part)>0):\n",
    "                split_y.append(split_y_part)\n",
    "                split_x.append(split_x_part)\n",
    "                split_y_part = []\n",
    "                split_x_part = []\n",
    "    \n",
    "    data_x_seq, data_y_seq = [], []\n",
    "    for i in range(len(split_x)):\n",
    "        data_x_part, data_y_part = [], []\n",
    "        for j in range(len(split_x[i])-timesteps):\n",
    "            x = split_x[i][j:j+timesteps]\n",
    "            y = split_y[i][j:j+timesteps]\n",
    "            data_x_part.append(x)\n",
    "            data_y_part.append(y)\n",
    "        if(len(data_x_part)>0):\n",
    "            data_x_seq.append(data_x_part)\n",
    "            data_y_seq.append(data_y_part)\n",
    "    \n",
    "    return data_x_seq, data_y_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 11, '1L', 'NA'], [1, 12, '1L', 'NA'], [1, 13, '1L', 'NA'], [1, 14, '1L', 'NA'], [1, 11, '2R', 'NA'], [1, 12, '2R', 'NA'], [1, 13, '2R', 'NA'], [1, 14, '2R', 'NA'], [2, 11, '1L', 'NA'], [2, 12, '1L', 'NA'], [2, 13, '1L', 'NA'], [2, 14, '1L', 'NA'], [2, 11, '2R', 'NA'], [2, 12, '2R', 'NA'], [2, 13, '2R', 'NA'], [2, 14, '2R', 'NA'], [3, 11, '1L', 'NA'], [3, 12, '1L', 'NA'], [3, 13, '1L', 'NA'], [3, 14, '1L', 'NA'], [3, 11, '2R', 'NA'], [3, 12, '2R', 'NA'], [3, 13, '2R', 'NA'], [3, 14, '2R', 'NA'], [4, 11, '1L', 'NA'], [4, 12, '1L', 'NA'], [4, 13, '1L', 'NA'], [4, 14, '1L', 'NA'], [4, 11, '2R', 'NA'], [4, 12, '2R', 'NA'], [4, 13, '2R', 'NA'], [4, 14, '2R', 'NA'], [5, 11, '1L', 'NA'], [5, 12, '1L', 'NA'], [5, 13, '1L', 'NA'], [5, 14, '1L', 'NA'], [5, 11, '2R', 'NA'], [5, 12, '2R', 'NA'], [5, 13, '2R', 'NA'], [5, 14, '2R', 'NA'], [6, 11, '1L', 'NA'], [6, 12, '1L', 'NA'], [6, 13, '1L', 'NA'], [6, 14, '1L', 'NA'], [6, 11, '2R', 'NA'], [6, 12, '2R', 'NA'], [6, 13, '2R', 'NA'], [6, 14, '2R', 'NA']]\n"
     ]
    }
   ],
   "source": [
    "all_train_data_list = []\n",
    "#[4, 6, '2R', 'WC']\n",
    "for i in range(1,7): #1,2,3,5,6,  7,8,  9, 10\n",
    "    all_train_data_list.append([i, 11, '1L', 'NA'])\n",
    "    all_train_data_list.append([i, 12, '1L', 'NA'])\n",
    "    all_train_data_list.append([i, 13, '1L', 'NA'])\n",
    "    all_train_data_list.append([i, 14, '1L', 'NA'])\n",
    "#     step_data_list.append([i, 15, '1L', 'NA'])\n",
    "    all_train_data_list.append([i, 11, '2R', 'NA'])\n",
    "    all_train_data_list.append([i, 12, '2R', 'NA'])\n",
    "    all_train_data_list.append([i, 13, '2R', 'NA'])\n",
    "    all_train_data_list.append([i, 14, '2R', 'NA'])\n",
    "#     step_data_list.append([i, 15, '2R', 'NA'])    \n",
    "    \n",
    "print(all_train_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "[[1, 12, '1L', 'NA'], [1, 13, '1L', 'NA'], [1, 14, '1L', 'NA'], [1, 12, '2R', 'NA'], [1, 13, '2R', 'NA'], [1, 14, '2R', 'NA'], [2, 12, '1L', 'NA'], [2, 13, '1L', 'NA'], [2, 14, '1L', 'NA'], [2, 12, '2R', 'NA'], [2, 13, '2R', 'NA'], [2, 14, '2R', 'NA'], [3, 12, '1L', 'NA'], [3, 13, '1L', 'NA'], [3, 14, '1L', 'NA'], [3, 12, '2R', 'NA'], [3, 13, '2R', 'NA'], [3, 14, '2R', 'NA'], [4, 12, '1L', 'NA'], [4, 13, '1L', 'NA'], [4, 14, '1L', 'NA'], [4, 12, '2R', 'NA'], [4, 13, '2R', 'NA'], [4, 14, '2R', 'NA'], [5, 12, '1L', 'NA'], [5, 13, '1L', 'NA'], [5, 14, '1L', 'NA'], [5, 12, '2R', 'NA'], [5, 13, '2R', 'NA'], [5, 14, '2R', 'NA'], [6, 12, '1L', 'NA'], [6, 13, '1L', 'NA'], [6, 14, '1L', 'NA'], [6, 12, '2R', 'NA'], [6, 13, '2R', 'NA'], [6, 14, '2R', 'NA']]\n",
      "-----\n",
      "12\n",
      "[[1, 11, '1L', 'NA'], [1, 11, '2R', 'NA'], [2, 11, '1L', 'NA'], [2, 11, '2R', 'NA'], [3, 11, '1L', 'NA'], [3, 11, '2R', 'NA'], [4, 11, '1L', 'NA'], [4, 11, '2R', 'NA'], [5, 11, '1L', 'NA'], [5, 11, '2R', 'NA'], [6, 11, '1L', 'NA'], [6, 11, '2R', 'NA']]\n",
      "=====\n",
      "36\n",
      "[[1, 11, '1L', 'NA'], [1, 13, '1L', 'NA'], [1, 14, '1L', 'NA'], [1, 11, '2R', 'NA'], [1, 13, '2R', 'NA'], [1, 14, '2R', 'NA'], [2, 11, '1L', 'NA'], [2, 13, '1L', 'NA'], [2, 14, '1L', 'NA'], [2, 11, '2R', 'NA'], [2, 13, '2R', 'NA'], [2, 14, '2R', 'NA'], [3, 11, '1L', 'NA'], [3, 13, '1L', 'NA'], [3, 14, '1L', 'NA'], [3, 11, '2R', 'NA'], [3, 13, '2R', 'NA'], [3, 14, '2R', 'NA'], [4, 11, '1L', 'NA'], [4, 13, '1L', 'NA'], [4, 14, '1L', 'NA'], [4, 11, '2R', 'NA'], [4, 13, '2R', 'NA'], [4, 14, '2R', 'NA'], [5, 11, '1L', 'NA'], [5, 13, '1L', 'NA'], [5, 14, '1L', 'NA'], [5, 11, '2R', 'NA'], [5, 13, '2R', 'NA'], [5, 14, '2R', 'NA'], [6, 11, '1L', 'NA'], [6, 13, '1L', 'NA'], [6, 14, '1L', 'NA'], [6, 11, '2R', 'NA'], [6, 13, '2R', 'NA'], [6, 14, '2R', 'NA']]\n",
      "-----\n",
      "12\n",
      "[[1, 12, '1L', 'NA'], [1, 12, '2R', 'NA'], [2, 12, '1L', 'NA'], [2, 12, '2R', 'NA'], [3, 12, '1L', 'NA'], [3, 12, '2R', 'NA'], [4, 12, '1L', 'NA'], [4, 12, '2R', 'NA'], [5, 12, '1L', 'NA'], [5, 12, '2R', 'NA'], [6, 12, '1L', 'NA'], [6, 12, '2R', 'NA']]\n",
      "=====\n",
      "36\n",
      "[[1, 11, '1L', 'NA'], [1, 12, '1L', 'NA'], [1, 14, '1L', 'NA'], [1, 11, '2R', 'NA'], [1, 12, '2R', 'NA'], [1, 14, '2R', 'NA'], [2, 11, '1L', 'NA'], [2, 12, '1L', 'NA'], [2, 14, '1L', 'NA'], [2, 11, '2R', 'NA'], [2, 12, '2R', 'NA'], [2, 14, '2R', 'NA'], [3, 11, '1L', 'NA'], [3, 12, '1L', 'NA'], [3, 14, '1L', 'NA'], [3, 11, '2R', 'NA'], [3, 12, '2R', 'NA'], [3, 14, '2R', 'NA'], [4, 11, '1L', 'NA'], [4, 12, '1L', 'NA'], [4, 14, '1L', 'NA'], [4, 11, '2R', 'NA'], [4, 12, '2R', 'NA'], [4, 14, '2R', 'NA'], [5, 11, '1L', 'NA'], [5, 12, '1L', 'NA'], [5, 14, '1L', 'NA'], [5, 11, '2R', 'NA'], [5, 12, '2R', 'NA'], [5, 14, '2R', 'NA'], [6, 11, '1L', 'NA'], [6, 12, '1L', 'NA'], [6, 14, '1L', 'NA'], [6, 11, '2R', 'NA'], [6, 12, '2R', 'NA'], [6, 14, '2R', 'NA']]\n",
      "-----\n",
      "12\n",
      "[[1, 13, '1L', 'NA'], [1, 13, '2R', 'NA'], [2, 13, '1L', 'NA'], [2, 13, '2R', 'NA'], [3, 13, '1L', 'NA'], [3, 13, '2R', 'NA'], [4, 13, '1L', 'NA'], [4, 13, '2R', 'NA'], [5, 13, '1L', 'NA'], [5, 13, '2R', 'NA'], [6, 13, '1L', 'NA'], [6, 13, '2R', 'NA']]\n",
      "=====\n",
      "36\n",
      "[[1, 11, '1L', 'NA'], [1, 12, '1L', 'NA'], [1, 13, '1L', 'NA'], [1, 11, '2R', 'NA'], [1, 12, '2R', 'NA'], [1, 13, '2R', 'NA'], [2, 11, '1L', 'NA'], [2, 12, '1L', 'NA'], [2, 13, '1L', 'NA'], [2, 11, '2R', 'NA'], [2, 12, '2R', 'NA'], [2, 13, '2R', 'NA'], [3, 11, '1L', 'NA'], [3, 12, '1L', 'NA'], [3, 13, '1L', 'NA'], [3, 11, '2R', 'NA'], [3, 12, '2R', 'NA'], [3, 13, '2R', 'NA'], [4, 11, '1L', 'NA'], [4, 12, '1L', 'NA'], [4, 13, '1L', 'NA'], [4, 11, '2R', 'NA'], [4, 12, '2R', 'NA'], [4, 13, '2R', 'NA'], [5, 11, '1L', 'NA'], [5, 12, '1L', 'NA'], [5, 13, '1L', 'NA'], [5, 11, '2R', 'NA'], [5, 12, '2R', 'NA'], [5, 13, '2R', 'NA'], [6, 11, '1L', 'NA'], [6, 12, '1L', 'NA'], [6, 13, '1L', 'NA'], [6, 11, '2R', 'NA'], [6, 12, '2R', 'NA'], [6, 13, '2R', 'NA']]\n",
      "-----\n",
      "12\n",
      "[[1, 14, '1L', 'NA'], [1, 14, '2R', 'NA'], [2, 14, '1L', 'NA'], [2, 14, '2R', 'NA'], [3, 14, '1L', 'NA'], [3, 14, '2R', 'NA'], [4, 14, '1L', 'NA'], [4, 14, '2R', 'NA'], [5, 14, '1L', 'NA'], [5, 14, '2R', 'NA'], [6, 14, '1L', 'NA'], [6, 14, '2R', 'NA']]\n",
      "=====\n"
     ]
    }
   ],
   "source": [
    "step_train_data_list = []\n",
    "step_valid_data_list = []\n",
    "for i in range(11, 15):\n",
    "    step_train_data_list_part = [j for j in all_train_data_list if j[1]!=i]\n",
    "    step_valid_data_list_part = [j for j in all_train_data_list if j[1]==i]\n",
    "    print(len(step_train_data_list_part))\n",
    "    print(step_train_data_list_part)\n",
    "    print('-----')\n",
    "    print(len(step_valid_data_list_part))\n",
    "    print(step_valid_data_list_part)\n",
    "    print('=====')\n",
    "    step_train_data_list.append(step_train_data_list_part)\n",
    "    step_valid_data_list.append(step_valid_data_list_part)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "66949\n",
      "67205\n",
      "70644\n",
      "70900\n",
      "66239\n",
      "66495\n",
      "61833\n",
      "62089\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "train_x_list, train_y_list = [], []\n",
    "print(batch_size)\n",
    "\n",
    "for step_train_data in step_train_data_list:\n",
    "    data_x, data_y = [], []\n",
    "    \n",
    "    for i in step_train_data:\n",
    "        data_x_segement, data_y_segement = add_data(i[0], i[1], i[2], i[3])\n",
    "        for dx in data_x_segement:\n",
    "            data_x.extend(dx)\n",
    "        for dy in data_y_segement:\n",
    "            data_y.extend(dy)\n",
    "    \n",
    "    print(len(data_x))\n",
    "#     print(len(data_y))\n",
    "    \n",
    "    order = list(range(0,len(data_x),1))\n",
    "    random.shuffle(order)\n",
    "\n",
    "    train_x = [data_x[i] for i in order]\n",
    "#     train_x.extend([i for i in train_x[:batch_size]])\n",
    "    train_x.extend([train_x[i] for i in range(0, batch_size)])\n",
    "    train_y = [data_y[i] for i in order]\n",
    "#     train_y.extend([i for i in train_y[:batch_size]])\n",
    "    train_y.extend([train_y[i] for i in range(0, batch_size)])\n",
    "\n",
    "    print(len(train_x))\n",
    "    \n",
    "    train_x_list.append(train_x)\n",
    "    train_y_list.append(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "47\n",
      "56\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "valid_x_list, valid_y_list = [], []\n",
    "\n",
    "for step_valid_data in step_valid_data_list:\n",
    "    valid_x, valid_y=[], []\n",
    "    for i in step_valid_data:\n",
    "        data_x_segement, data_y_segement = add_data(i[0], i[1], i[2], i[3])\n",
    "        valid_x.extend(data_x_segement)\n",
    "        valid_y.extend(data_y_segement)\n",
    "    \n",
    "    print(len(valid_x))\n",
    "#     print(len(valid_y))\n",
    "    \n",
    "    valid_x_list.append(valid_x)\n",
    "    valid_y_list.append(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 15, '1L', 'NA'], [1, 15, '2R', 'NA'], [2, 15, '1L', 'NA'], [2, 15, '2R', 'NA'], [3, 15, '1L', 'NA'], [3, 15, '2R', 'NA'], [4, 15, '1L', 'NA'], [4, 15, '2R', 'NA'], [5, 15, '1L', 'NA'], [5, 15, '2R', 'NA'], [6, 15, '1L', 'NA'], [6, 15, '2R', 'NA']]\n"
     ]
    }
   ],
   "source": [
    "step_test_list = []\n",
    "for i in range(1,7):\n",
    "#     step_test_list.append([i, 11, '1L', 'NA'])\n",
    "#     step_test_list.append([i, 12, '1L', 'NA'])\n",
    "#     step_test_list.append([i, 13, '1L', 'NA'])\n",
    "#     step_test_list.append([i, 14, '1L', 'NA'])\n",
    "    step_test_list.append([i, 15, '1L', 'NA'])\n",
    "#     step_test_list.append([i, 11, '2R', 'NA'])\n",
    "#     step_test_list.append([i, 12, '2R', 'NA'])\n",
    "#     step_test_list.append([i, 13, '2R', 'NA'])\n",
    "#     step_test_list.append([i, 14, '2R', 'NA'])\n",
    "    step_test_list.append([i, 15, '2R', 'NA'])    \n",
    "        \n",
    "print(step_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "54\n",
      "[30, 66, 725, 25, 30, 66, 725, 25, 63, 1037, 57, 8, 63, 1037, 57, 8, 1085, 220, 1085, 220, 148, 1024, 37, 971, 72, 787, 54, 707, 148, 1024, 37, 971, 72, 787, 54, 707, 289, 577, 87, 343, 231, 1049, 289, 577, 87, 343, 231, 1049, 554, 1091, 724, 554, 1091, 724]\n"
     ]
    }
   ],
   "source": [
    "test_x, test_y=[], []\n",
    "for i in step_test_list:\n",
    "    data_x_segement, data_y_segement = add_data(i[0], i[1], i[2], i[3])\n",
    "    test_x.extend(data_x_segement)\n",
    "    test_y.extend(data_y_segement)\n",
    "#     test_x.append(data_x_segement)\n",
    "#     test_y.append(data_y_segement)\n",
    "    \n",
    "print(len(test_x))\n",
    "print(len(test_y))\n",
    "\n",
    "print([len(i) for i in test_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 100, 1)\n",
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "NUM_LAYERS=2\n",
    "\n",
    "def LstmCell():\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(num_hidden)#, forget_bias=1.0)\n",
    "    cell = tf.contrib.rnn.DropoutWrapper(lstm_cell, output_keep_prob=0.5)\n",
    "    return cell\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default(), tf.device('/gpu:0'):\n",
    "    # tf Graph input\n",
    "    X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "    Y = tf.placeholder(\"float\", [None, timesteps, num_output])\n",
    "    \n",
    "    # Define weights\n",
    "    weights = {\n",
    "        'out': tf.Variable(tf.random_normal([num_hidden, num_output]))\n",
    "    }\n",
    "    biases = {\n",
    "        'out': tf.Variable(tf.random_normal([num_output]))\n",
    "    }\n",
    "    \n",
    "    def RNN(x, weights, biases):\n",
    "        x = tf.unstack(x, timesteps, 1)\n",
    "        cell = tf.contrib.rnn.MultiRNNCell([LstmCell() for _ in range(NUM_LAYERS)])\n",
    "        outputs, state = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "        outputs = tf.transpose(outputs, [1,0,2])\n",
    "\n",
    "#         return tf.matmul(outputs[-2], weights['out']) + biases['out']\n",
    "        ret = []\n",
    "#         print(outputs.shape)\n",
    "        for i in range(0, timesteps):\n",
    "            ret.append(tf.matmul(outputs[i], weights['out']) + biases['out'])\n",
    "            \n",
    "        return ret\n",
    "\n",
    "#         return np.array(ret)\n",
    "    \n",
    "    logits = RNN(X, weights, biases)\n",
    "    logits = tf.transpose(logits, [1,0,2])\n",
    "#     print(len(logits))\n",
    "    print(logits.shape)\n",
    "    print(logits[0].shape)\n",
    "    mean_train = tf.reduce_mean(X)\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.squared_difference(logits, Y))\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(loss)\n",
    "    \n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_accuarcy(y, _y):\n",
    "#     print(len(y))\n",
    "#     print(len(y[0]))\n",
    "#     print(len(y[0][0]))\n",
    "#     print(y[0][0])\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for i in range(len(y[0])):\n",
    "        total += 1\n",
    "        if(y[0][i][0] == round(_y[0][i][0])):\n",
    "            count += 1\n",
    "    for i in range(1, len(y)):\n",
    "        total += 1\n",
    "        if(y[i][-1][0] == round(_y[i][-1][0])):\n",
    "            count += 1;\n",
    "    return(count*1.0/total)\n",
    "#     print(\"train accuarcy : \", count/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation  0\n",
      "Initialized\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Blas GEMM launch failed : a.shape=(256, 106), b.shape=(106, 400), m=256, n=400, k=106\n\t [[Node: rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/concat, rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/MatMul/Enter)]]\n\t [[Node: Mean_1/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_5881_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/MatMul', defined at:\n  File \"/home/ziyi/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ziyi/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-838670479d78>\", line 38, in <module>\n    logits = RNN(X, weights, biases)\n  File \"<ipython-input-11-838670479d78>\", line 25, in RNN\n    outputs, state = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 614, in dynamic_rnn\n    dtype=dtype)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 777, in _dynamic_rnn_loop\n    swap_memory=swap_memory)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2816, in while_loop\n    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2640, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2590, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 762, in _time_step\n    (output, new_state) = call_cell()\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 748, in <lambda>\n    call_cell = lambda: cell(input_t, state)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 183, in __call__\n    return super(RNNCell, self).__call__(inputs, state)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 575, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 1066, in call\n    cur_inp, new_state = cell(cur_inp, cur_state)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 183, in __call__\n    return super(RNNCell, self).__call__(inputs, state)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 575, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 441, in call\n    value=self._linear([inputs, h]), num_or_size_splits=4, axis=1)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 1189, in __call__\n    res = math_ops.matmul(array_ops.concat(args, 1), self._weights)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1891, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 2437, in _mat_mul\n    name=name)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(256, 106), b.shape=(106, 400), m=256, n=400, k=106\n\t [[Node: rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/concat, rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/MatMul/Enter)]]\n\t [[Node: Mean_1/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_5881_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(256, 106), b.shape=(106, 400), m=256, n=400, k=106\n\t [[Node: rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/concat, rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/MatMul/Enter)]]\n\t [[Node: Mean_1/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_5881_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-11bc416564fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_start\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_start\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mtrain_accuarcy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcal_accuarcy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_start\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(256, 106), b.shape=(106, 400), m=256, n=400, k=106\n\t [[Node: rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/concat, rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/MatMul/Enter)]]\n\t [[Node: Mean_1/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_5881_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/MatMul', defined at:\n  File \"/home/ziyi/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ziyi/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-838670479d78>\", line 38, in <module>\n    logits = RNN(X, weights, biases)\n  File \"<ipython-input-11-838670479d78>\", line 25, in RNN\n    outputs, state = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 614, in dynamic_rnn\n    dtype=dtype)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 777, in _dynamic_rnn_loop\n    swap_memory=swap_memory)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2816, in while_loop\n    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2640, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2590, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 762, in _time_step\n    (output, new_state) = call_cell()\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 748, in <lambda>\n    call_cell = lambda: cell(input_t, state)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 183, in __call__\n    return super(RNNCell, self).__call__(inputs, state)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 575, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 1066, in call\n    cur_inp, new_state = cell(cur_inp, cur_state)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 183, in __call__\n    return super(RNNCell, self).__call__(inputs, state)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 575, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 441, in call\n    value=self._linear([inputs, h]), num_or_size_splits=4, axis=1)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 1189, in __call__\n    res = math_ops.matmul(array_ops.concat(args, 1), self._weights)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1891, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 2437, in _mat_mul\n    name=name)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/ziyi/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(256, 106), b.shape=(106, 400), m=256, n=400, k=106\n\t [[Node: rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/concat, rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/MatMul/Enter)]]\n\t [[Node: Mean_1/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_5881_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "training_steps = 4001\n",
    "valid_loss_list, valid_logits_list = [], []\n",
    "# test_loss_list, test_logits_list = [], []\n",
    "\n",
    "for i in range(0,len(valid_x_list)):\n",
    "    batch_start=0\n",
    "    print(\"cross validation \", i)\n",
    "#     batch_start = 0\n",
    "    train_x = train_x_list[i]\n",
    "    train_y = train_y_list[i]\n",
    "    train_length = len(train_x_list[i])-256\n",
    "    valid_x = valid_x_list[i]\n",
    "    valid_y = valid_y_list[i]\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    with tf.Session(graph=graph, config=config) as session:\n",
    "#         saver.restore(session, tf.train.latest_checkpoint('lstm_check'))\n",
    "        saver.restore(session, \"lstm_check/my-model-gpu-error-metric-dropout2-wc-10fold-2.ckpt-00\")\n",
    "#         tf.global_variables_initializer().run()\n",
    "        print('Initialized')\n",
    "        for step in range(training_steps):      \n",
    "            feed_dict = {X: train_x[batch_start:batch_start+batch_size], Y: train_y[batch_start:batch_start+batch_size]}\n",
    "            _, l, predictions, m = session.run([optimizer, loss, logits, mean_train], feed_dict = feed_dict)\n",
    "            if (step % 200 == 0):\n",
    "                train_accuarcy = cal_accuarcy(train_y[batch_start:batch_start+batch_size], predictions)\n",
    "                print('Loss at step %d: %f, train accuarcy : %f' % (step, l, train_accuarcy))\n",
    "                #train accuarcy\n",
    "            if (step % 500 == 0):\n",
    "                saver.save(session, 'lstm_check/my-model-gpu-error-metric-dropout2-wc-10fold-'+str(i+1)+'.ckpt', global_step=step)\n",
    "            batch_start += batch_size\n",
    "            if(batch_start>=train_length):\n",
    "                batch_start -=train_length\n",
    "        valid_loss, valid_logits = [], []\n",
    "        for j in range(len(valid_x)):\n",
    "            valid_loss_part, valid_logits_part = session.run([loss,logits], feed_dict={X: valid_x[j], Y: valid_y[j]})\n",
    "            valid_loss.append(valid_loss_part)\n",
    "            valid_logits.append(valid_logits_part)\n",
    "\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        valid_logits_list.append(valid_logits)\n",
    "\n",
    "#         test_loss, test_logits = [], []\n",
    "#         for j in range(len(test_x)):\n",
    "#             test_loss_part, test_logits_part = session.run([loss,logits], feed_dict={X: test_x[j], Y: test_y[j]})\n",
    "#             test_loss.append(test_loss_part)\n",
    "#             test_logits.append(test_logits_part)\n",
    "\n",
    "#         test_loss_list.append(test_loss)\n",
    "#         test_logits_list.append(test_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Error Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16270\n",
      "26754\n",
      "valid accuarcy :  0.608133363235404\n",
      "Step number for each segement\n",
      "[10, 58, 8, 10, 58, 8, 8, 84, 12, 7, 8, 84, 12, 7, 79, 22, 79, 22, 20, 80, 10, 79, 11, 60, 10, 54, 20, 80, 10, 79, 11, 60, 10, 54, 26, 44, 20, 27, 21, 82, 26, 44, 20, 27, 21, 82, 30, 77, 6, 30, 77, 6]\n",
      "[14, 101, 19, 12, 85, 9, 8, 169, 15, 14, 10, 117, 12, 11, 117, 39, 122, 39, 29, 147, 19, 130, 15, 88, 14, 93, 35, 112, 13, 104, 10, 79, 13, 73, 49, 77, 36, 41, 36, 129, 34, 65, 27, 36, 24, 131, 51, 143, 13, 38, 104, 11]\n",
      "52\n",
      "52\n",
      "1047\n",
      "[4, 45, 10, 2, 27, 0, 0, 83, 3, 6, 2, 32, 0, 3, 43, 15, 43, 14, 8, 69, 7, 51, 4, 32, 4, 39, 17, 31, 2, 25, 0, 20, 3, 22, 23, 34, 15, 16, 15, 56, 8, 22, 4, 6, 2, 50, 23, 66, 5, 8, 25, 3]\n",
      "52\n",
      "1043\n",
      "[4, 43, 11, 2, 27, 1, 0, 85, 3, 7, 2, 33, 0, 4, 38, 17, 43, 17, 9, 67, 9, 51, 4, 28, 4, 39, 15, 32, 3, 25, 0, 19, 3, 19, 23, 33, 16, 14, 15, 47, 8, 21, 7, 9, 3, 49, 21, 66, 7, 8, 27, 5]\n",
      "error : \n",
      "total undercount metric 1:\t 0.031216931216931216\n",
      "total overcount metric 1:\t 0.5825396825396826\n",
      "total undercount metric 2:\t 0.10476190476190476\n",
      "total overcount metric 2:\t 0.656084656084656\n",
      "total undercount metric 3:\t 0.0005291005291005291\n",
      "total overcount metric 3:\t 0.5518518518518518\n",
      "==============================================================\n",
      "13852\n",
      "22564\n",
      "valid accuarcy :  0.6138982449920227\n",
      "Step number for each segement\n",
      "[9, 49, 9, 49, 7, 69, 8, 6, 7, 69, 8, 6, 73, 19, 73, 19, 18, 72, 9, 70, 9, 52, 9, 18, 72, 9, 70, 9, 52, 9, 48, 23, 39, 18, 24, 19, 73, 23, 39, 18, 24, 19, 73, 34, 67, 34, 67]\n",
      "[13, 90, 9, 42, 13, 108, 13, 15, 8, 64, 9, 10, 131, 34, 74, 23, 28, 150, 14, 118, 17, 87, 12, 24, 45, 12, 46, 10, 27, 8, 46, 34, 55, 33, 44, 38, 145, 36, 36, 17, 31, 20, 78, 58, 118, 52, 32]\n",
      "47\n",
      "47\n",
      "960\n",
      "[4, 42, 5, 22, 3, 39, 4, 8, 4, 36, 4, 4, 56, 14, 41, 11, 7, 78, 4, 49, 6, 37, 4, 13, 16, 5, 21, 0, 15, 3, 21, 12, 17, 14, 19, 20, 75, 20, 15, 7, 15, 10, 37, 24, 52, 33, 14]\n",
      "47\n",
      "657\n",
      "[4, 41, 0, 0, 6, 39, 5, 9, 1, 0, 1, 4, 58, 15, 1, 4, 10, 78, 5, 48, 8, 35, 3, 6, 0, 3, 0, 1, 0, 0, 0, 11, 16, 15, 20, 19, 72, 13, 0, 0, 7, 1, 5, 24, 51, 18, 0]\n",
      "error : \n",
      "total undercount metric 1:\t 0.2975\n",
      "total overcount metric 1:\t 0.626875\n",
      "total undercount metric 2:\t 0.241875\n",
      "total overcount metric 2:\t 0.57125\n",
      "total undercount metric 3:\t 0.08125\n",
      "total overcount metric 3:\t 0.410625\n",
      "==============================================================\n",
      "23900\n",
      "27860\n",
      "valid accuarcy :  0.8578607322325915\n",
      "Step number for each segement\n",
      "[8, 10, 58, 8, 10, 58, 81, 12, 7, 81, 12, 7, 83, 23, 83, 23, 17, 78, 10, 76, 10, 56, 9, 55, 17, 78, 10, 76, 10, 56, 9, 55, 25, 19, 19, 19, 26, 20, 76, 25, 19, 19, 19, 26, 20, 76, 15, 15, 7, 46, 49, 15, 15, 7, 46, 49]\n",
      "[7, 10, 57, 8, 13, 57, 84, 12, 7, 80, 22, 9, 83, 23, 83, 28, 17, 80, 11, 79, 11, 57, 9, 55, 17, 81, 11, 78, 10, 57, 10, 56, 25, 18, 18, 18, 27, 20, 78, 27, 20, 19, 27, 26, 21, 82, 15, 15, 7, 48, 49, 15, 15, 7, 51, 51]\n",
      "56\n",
      "56\n",
      "313\n",
      "[1, 3, 9, 1, 2, 2, 29, 2, 2, 6, 11, 0, 19, 5, 5, 5, 5, 21, 2, 21, 2, 22, 4, 19, 0, 7, 0, 2, 0, 2, 0, 0, 6, 4, 1, 2, 7, 5, 18, 0, 0, 1, 8, 0, 0, 4, 5, 6, 2, 13, 11, 3, 1, 1, 3, 3]\n",
      "56\n",
      "70\n",
      "[0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 10, 2, 0, 0, 0, 5, 0, 2, 1, 3, 1, 1, 0, 0, 0, 3, 1, 2, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 2, 2, 1, 0, 8, 0, 1, 6, 0, 0, 0, 2, 0, 0, 0, 0, 5, 2]\n",
      "error : \n",
      "total undercount metric 1:\t 0.15931108719052745\n",
      "total overcount metric 1:\t 0.19321851453175456\n",
      "total undercount metric 2:\t 0.010764262648008612\n",
      "total overcount metric 2:\t 0.044671689989235736\n",
      "total undercount metric 3:\t 0.003767491926803014\n",
      "total overcount metric 3:\t 0.03767491926803014\n",
      "==============================================================\n",
      "15383\n",
      "32266\n",
      "valid accuarcy :  0.47675571809334905\n",
      "Step number for each segement\n",
      "[9, 11, 66, 7, 9, 11, 66, 7, 9, 93, 11, 8, 9, 93, 11, 8, 93, 25, 93, 25, 19, 93, 12, 77, 13, 67, 11, 62, 19, 93, 12, 77, 13, 67, 11, 62, 7, 27, 48, 23, 34, 25, 50, 7, 27, 48, 23, 34, 25, 50, 44, 86, 60, 44, 86, 60]\n",
      "[11, 12, 66, 8, 10, 11, 67, 8, 10, 94, 14, 8, 10, 93, 13, 10, 94, 26, 125, 27, 19, 93, 12, 79, 13, 72, 14, 74, 22, 111, 19, 100, 16, 77, 15, 75, 8, 28, 50, 22, 34, 30, 54, 9, 37, 57, 25, 38, 27, 77, 44, 104, 74, 69, 117, 91]\n",
      "56\n",
      "56\n",
      "1097\n",
      "[3, 5, 32, 3, 0, 1, 23, 0, 3, 46, 7, 4, 0, 28, 3, 1, 45, 12, 66, 11, 8, 46, 6, 38, 5, 35, 6, 37, 7, 59, 13, 59, 7, 31, 6, 14, 3, 13, 25, 10, 14, 15, 25, 2, 11, 12, 2, 6, 4, 39, 21, 50, 36, 35, 62, 42]\n",
      "56\n",
      "344\n",
      "[2, 1, 0, 1, 1, 0, 1, 1, 1, 1, 3, 0, 1, 0, 2, 2, 1, 1, 32, 2, 0, 0, 0, 2, 0, 5, 3, 12, 3, 18, 7, 23, 3, 10, 4, 13, 1, 1, 2, 0, 0, 5, 4, 2, 10, 9, 2, 4, 2, 27, 0, 18, 14, 25, 31, 31]\n",
      "error : \n",
      "total undercount metric 1:\t 0.3724770642201835\n",
      "total overcount metric 1:\t 0.5298165137614679\n",
      "total undercount metric 2:\t 0.04036697247706422\n",
      "total overcount metric 2:\t 0.19770642201834862\n",
      "total undercount metric 3:\t 0.00045871559633027525\n",
      "total overcount metric 3:\t 0.1577981651376147\n",
      "==============================================================\n"
     ]
    }
   ],
   "source": [
    "# print(len(valid_logits), len(valid_logits[0]), len(valid_logits[0][0]))\n",
    "\n",
    "# print(len(valid_y))\n",
    "# print(len(valid_y[0]))\n",
    "# print(len(valid_y[0][0]))  \n",
    "\n",
    "m1u, m1o, m2u, m2o, m3u, m3o = [], [], [], [], [], []\n",
    "    \n",
    "for k in range(len(valid_logits_list)):\n",
    "    \n",
    "    valid_logits = valid_logits_list[k]\n",
    "    valid_y = valid_y_list[k]    \n",
    "    \n",
    "    valid_y_seq_list, valid_logits_bin_list = [], []\n",
    "\n",
    "    for t in valid_logits:  \n",
    "        t_all = [i for i in t[0]]\n",
    "        t_all.extend([i[-1] for i in t[1:]])\n",
    "    #     print(len(t_all)-len(t))\n",
    "\n",
    "        valid_logits_part = [[round(i[0])] for i in t_all]\n",
    "        for i in range(1, len(valid_logits_part)-1):\n",
    "            if(valid_logits_part[i-1][0]!=valid_logits_part[i][0] and valid_logits_part[i-1][0]==valid_logits_part[i+1][0]):\n",
    "                valid_logits_part[i][0]=valid_logits_part[i-1][0]  \n",
    "\n",
    "        valid_logits_bin_list.append(valid_logits_part)\n",
    "\n",
    "    for t in valid_y:  \n",
    "        t_all = [i for i in t[0]]\n",
    "        t_all.extend([i[-1] for i in t[1:]])\n",
    "        valid_y_seq_list.append(t_all)\n",
    "\n",
    "    # print(valid_y_seq_list)\n",
    "\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for i in range(0, len(valid_y_seq_list)):\n",
    "        total += len(valid_y_seq_list[i])\n",
    "    #     print(len(valid_y_seq_list[i]), len(valid_logits_bin_list[i]))\n",
    "\n",
    "        for j in range(0, len(valid_y_seq_list[i])):\n",
    "            if(valid_y_seq_list[i][j][0] == valid_logits_bin_list[i][j][0]):\n",
    "                count += 1\n",
    "\n",
    "    print(count)\n",
    "    print(total)\n",
    "    print(\"valid accuarcy : \", count*1.0/total)\n",
    "    \n",
    "    #===========================================\n",
    "    step_time_actual, step_time_predict= [], []\n",
    "    step_time_actual_gap = []\n",
    "\n",
    "    #valid_y_seq_list, valid_logits_bin_list\n",
    "    for i in range(0, len(valid_y_seq_list)):\n",
    "        step_time_actual_part, step_time_predict_part= [], []\n",
    "        for j in range(1, len(valid_y_seq_list[i])):\n",
    "            if(abs(valid_y_seq_list[i][j][0]-valid_y_seq_list[i][j-1][0])>0.5):\n",
    "                step_time_actual_part.append(j)\n",
    "        #     if(abs(valid_logits[i][0]-valid_logits[i-1][0])>0.5):\n",
    "            if(abs(valid_logits_bin_list[i][j][0]-valid_logits_bin_list[i][j-1][0])>0.5):\n",
    "                step_time_predict_part.append(j)\n",
    "        step_time_actual.append(step_time_actual_part)\n",
    "        step_time_predict.append(step_time_predict_part)\n",
    "\n",
    "        step_time_actual_gap_part = []\n",
    "        step_time_actual_gap_part.append(0)\n",
    "    #     step_time_actual_gap_part.append(step_time_actual_part[0]/2.0)\n",
    "        for i in range(1, len(step_time_actual_part)):\n",
    "            step_time_actual_gap_part.append((step_time_actual_part[i-1]+step_time_actual_part[i])/2.0)\n",
    "        step_time_actual_gap_part.append(step_time_actual_part[-1]*2)\n",
    "        step_time_actual_gap.append(step_time_actual_gap_part)\n",
    "\n",
    "    print('Step number for each segement')\n",
    "    print([len(i) for i in step_time_actual])   \n",
    "    print([len(i) for i in step_time_predict])\n",
    "    \n",
    "    #===================================================\n",
    "    total_step_count = sum([len(i) for i in step_time_actual])\n",
    "    metric1_undercount = 0\n",
    "    metric2_undercount = 0\n",
    "    metric3_undercount = 0\n",
    "    metric1_overcount = 0\n",
    "    metric2_overcount = 0\n",
    "    metric3_overcount = 0\n",
    "    \n",
    "    metric1_overcount_list = []\n",
    "    metric2_overcount_list = []\n",
    "    metric3_overcount_list = []\n",
    "\n",
    "    print(len(valid_y))\n",
    "\n",
    "    for i in range(len(valid_y)):\n",
    "        step_count = len(step_time_actual[i])\n",
    "        undercount = 0\n",
    "        overcount = 0\n",
    "        \n",
    "        metric1_overcount += len([t for t in step_time_predict[i] if t<step_time_actual[i][0]])\n",
    "        for j in range(1, step_count):\n",
    "            gap_count = [t for t in step_time_predict[i] if t>=step_time_actual[i][j-1] and t<step_time_actual[i][j]]\n",
    "        #     print(gap_count)\n",
    "            if(len(gap_count)>1):\n",
    "                overcount += len(gap_count)-1\n",
    "            if(len(gap_count)<1):\n",
    "                undercount += 1\n",
    "        gap_count = [t for t in step_time_predict[i] if t>=step_time_actual[i][-1]]\n",
    "        if(len(gap_count)>1):\n",
    "            overcount += len(gap_count)-1\n",
    "        if(len(gap_count)<1):\n",
    "            undercount += 1\n",
    "\n",
    "        metric1_undercount += undercount\n",
    "        metric1_overcount += overcount\n",
    "        metric1_overcount_list.append(overcount)\n",
    "\n",
    "        undercount = 0\n",
    "        overcount = 0\n",
    "        for j in range(1, len(step_time_actual_gap[i])):\n",
    "            gap_count = [t for t in step_time_predict[i] if t>=step_time_actual_gap[i][j-1] and t<step_time_actual_gap[i][j]]\n",
    "        #     print(gap_count)\n",
    "            if(len(gap_count)>1):\n",
    "                overcount += (len(gap_count)-1)\n",
    "            if(len(gap_count)<1):\n",
    "                undercount += 1    \n",
    "\n",
    "        metric2_undercount += undercount\n",
    "        metric2_overcount += overcount  \n",
    "        metric2_overcount_list.append(overcount)\n",
    "\n",
    "        diff = len(step_time_predict[i])-len(step_time_actual[i])\n",
    "#         print(step_time_actual[i])\n",
    "#         print(step_time_predict[i])\n",
    "#         print('------')\n",
    "\n",
    "        if(diff<0):\n",
    "    #         print('segement undercount : ', 1-len(step_time_predict[i])*1.0/len(step_time_actual[i]))\n",
    "            metric3_undercount -= diff\n",
    "            metric3_overcount_list.append(0)\n",
    "    #     if(diff>=0):\n",
    "        else:\n",
    "    #         print('segement overcount : ', 1-len(step_time_actual[i])*1.0/len(step_time_predict[i]))\n",
    "            metric3_overcount += diff\n",
    "            metric3_overcount_list.append(diff)\n",
    "\n",
    "    print(len(metric1_overcount_list))\n",
    "    print(sum(metric1_overcount_list))\n",
    "    print(metric1_overcount_list)\n",
    "    print(len(metric3_overcount_list))\n",
    "    print(sum(metric3_overcount_list))\n",
    "    print(metric3_overcount_list)\n",
    "\n",
    "    print('error : ')\n",
    "    print(\"total undercount metric 1:\\t\", metric1_undercount*1.0/total_step_count)\n",
    "    print(\"total overcount metric 1:\\t\", metric1_overcount*1.0/total_step_count)\n",
    "    print(\"total undercount metric 2:\\t\", metric2_undercount*1.0/total_step_count)\n",
    "    print(\"total overcount metric 2:\\t\", metric2_overcount*1.0/total_step_count)\n",
    "    print(\"total undercount metric 3:\\t\", metric3_undercount*1.0/total_step_count)\n",
    "    print(\"total overcount metric 3:\\t\", metric3_overcount*1.0/total_step_count)\n",
    "    \n",
    "    m1u.append(metric1_undercount*1.0/total_step_count)\n",
    "    m1o.append(metric1_overcount*1.0/total_step_count)\n",
    "    m2u.append(metric2_undercount*1.0/total_step_count)\n",
    "    m2o.append(metric2_overcount*1.0/total_step_count)\n",
    "    m3u.append(metric3_undercount*1.0/total_step_count)\n",
    "    m3o.append(metric3_overcount*1.0/total_step_count)\n",
    "    \n",
    "    \n",
    "    print(\"==============================================================\")\n",
    "\n",
    "filename = 'tmp/na_valid_timesteps='+str(timesteps)+'_trainingsteps='+str(training_steps)+'lr='+str(0.1)+'1.csv'\n",
    "with open(filename,\"w\") as csvfile: \n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    #columns_name\n",
    "    writer.writerow([\"cv0\",\"cv1\",\"cv2\",\"cv3\"])\n",
    "    #writerows\n",
    "    writer.writerows([m1u, m1o, m2u, m2o, m3u, m3o])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
